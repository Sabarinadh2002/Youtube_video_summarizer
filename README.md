# ðŸŽ¬â€¯AIâ€‘Based YouTube Videoâ€¯Summariser

This project lets you **paste any YouTube link** and instantly receive:

* **Summary** (1â€‘2 lines)  
* **Highlights** (emojiâ€‘bullet key points)  
* **Key Insights** (takeâ€‘aways)  
* **Optional translation** into 25â€¯+ languages  
* **Textâ€‘toâ€‘Speech** (Playâ€¯/â€¯Pauseâ€¯/â€¯Resume)

The system is split intoâ€¯two parts:

| Layer | Tech | Main file/command |
|-------|------|-------------------|
| **Backâ€‘end** | FastAPIÂ +Â Ollama (running the **LLaMAâ€¯3â€¯7B** model), Googleâ€‘Translate, YouTubeâ€‘Transcriptâ€‘API | `model/app.py` â†’ `python app.py` or `uvicorn app:app --reload` |
| **Frontâ€‘end** | Next.jsâ€¯(Reactâ€¯18), Tailwindâ€¯CSS, Framerâ€‘Motion | `npmâ€¯runâ€¯dev` |

---

## 1â€¯.â€¯Quick start

> **Prerequisites**  
> â€¢Â Pythonâ€¯3.9+â€ƒâ€¢Â Nodeâ€¯18+ /â€¯npm 9+â€ƒâ€¢Â Gitâ€ƒâ€¢Â Ollama (local LLM runtime â€“ <https://ollama.ai>)

```bash
# 1. Clone the repo
git clone https://github.com/<yourâ€‘username>/ytâ€‘summariser.git
cd ytâ€‘summariser

# 2. Install backâ€‘end deps
python -m venv .venv && source .venv/bin/activate   # optional virtualâ€‘env
pip install -r requirements.txt                     # or use the list below

# 3. Pull the LLaMAÂ 3.2 model (â‰ˆâ€¯4â€¯GB) for Ollama
ollama pull llama3.2                                # firstâ€‘run only

# 4. Install frontâ€‘end deps
npm install                                         # grabs React, Next, Tailwind, etc.

# 5. Open TWO terminals
# â”€â”€ TerminalÂ A â€“ start FastAPI (portÂ 8000)
python model/app.py                                 # or: uvicorn model.app:app --reload
# â”€â”€ TerminalÂ B â€“ start Next.js (portÂ 3000)
npm run dev

# 6. Visit http://localhost:3000  ðŸŽ‰
